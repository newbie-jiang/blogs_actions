# ===== å¯¼å…¥å¿…è¦çš„æ¨¡å— =====
import os
import numpy as np
import tensorflow as tf
from prepare_dataset import load_dataset            # åŠ è½½è‡ªå®šä¹‰æ•°æ®é›†åŠ è½½å‡½æ•°
from tensorflow.keras.callbacks import EarlyStopping
import random

# ===== å›ºå®šéšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯å¤ç° =====
SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)
random.seed(SEED)

# ===== å¯è°ƒå‚æ•°åŒºåŸŸ =====
DATA_DIR = "aug_data"           # æ•°æ®æ‰€åœ¨ç›®å½•
EPOCHS = 50                     # æœ€å¤§è®­ç»ƒè½®æ•°
BATCH_SIZE = 2                  # æ¯æ‰¹è®­ç»ƒæ ·æœ¬æ•°é‡
VALIDATION_SPLIT = 0.2          # éªŒè¯é›†æ¯”ä¾‹ï¼ˆ20%ï¼‰
LEARNING_RATE = 0.0005          # å­¦ä¹ ç‡ï¼Œå½±å“æ”¶æ•›é€Ÿåº¦  0.0005    
HIDDEN_UNITS = 30              # å…¨è¿æ¥å±‚ç¥ç»å…ƒä¸ªæ•°ï¼ˆç”¨äºåˆ†ç±»å†³ç­–ï¼‰ 30
PATIENCE = 5                    # éªŒè¯é›†æ—©åœè€å¿ƒè½®æ•°
# ==========================

# ===== åŠ è½½æ•°æ®é›† =====
X, y = load_dataset(DATA_DIR)   # åŠ è½½å›¾åƒå’Œå¯¹åº”æ ‡ç­¾
print(f"\nğŸ“¦ æ•°æ®é›†åŠ è½½å®Œæ¯•ï¼š{X.shape}, æ ‡ç­¾ï¼š{y.shape}")

# è¾“å‡ºæ ‡ç­¾åˆ†å¸ƒç»Ÿè®¡
unique, counts = np.unique(y, return_counts=True)
print("ğŸ¯ æ ‡ç­¾ç»Ÿè®¡ï¼š")
for u, c in zip(unique, counts):
    print(f"  ç±»åˆ« {u}: {c} ä¸ªæ ·æœ¬")

# ===== æ„å»ºæ¨¡å‹ç»“æ„ =====
def build_model():
    model = tf.keras.Sequential([

        # è¾“å…¥å±‚ï¼ˆ64x64 å•é€šé“å›¾åƒï¼‰
        tf.keras.layers.Input(shape=(64, 64, 1)),

        # å·ç§¯å±‚1ï¼šæå–ä½é˜¶ç‰¹å¾
        tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPooling2D(),

        # å·ç§¯å±‚2ï¼šæå–æ›´å¤æ‚çš„æ¨¡å¼
        tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPooling2D(),

        # æ‰å¹³åŒ–è¾“å‡ºï¼Œä¸ºå…¨è¿æ¥å±‚å‡†å¤‡è¾“å…¥
        tf.keras.layers.Flatten(),

        # å…¨è¿æ¥å±‚ï¼šæå–å…¨å±€ç‰¹å¾å¹¶ç”¨äºåˆ¤åˆ«
        tf.keras.layers.Dense(HIDDEN_UNITS, activation='relu'),

        # Dropout å±‚ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆ
        tf.keras.layers.Dropout(0.3),

        # è¾“å‡ºå±‚ï¼š1 ä¸ªç¥ç»å…ƒ + sigmoid æ¿€æ´»ï¼Œè¾“å‡ºæ¦‚ç‡ï¼ˆç”¨äºäºŒåˆ†ç±»ï¼‰
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])

    # ç¼–è¯‘æ¨¡å‹
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
        loss='binary_crossentropy',   # äºŒåˆ†ç±»æŸå¤±å‡½æ•°
        metrics=['accuracy']          # è¯„ä¼°æŒ‡æ ‡ä¸ºå‡†ç¡®ç‡
    )
    return model

# åˆ›å»ºæ¨¡å‹
model = build_model()

# è®¾ç½® EarlyStoppingï¼šéªŒè¯é›† loss å¤šæ¬¡ä¸æå‡å°±æå‰åœæ­¢è®­ç»ƒ
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=PATIENCE,
    restore_best_weights=True,
    verbose=1
)

# ===== æ¨¡å‹è®­ç»ƒ =====
print("\nğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
history = model.fit(
    X, y,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    validation_split=VALIDATION_SPLIT,
    callbacks=[early_stop],
    verbose=1
)

# ===== ä¿å­˜ Keras åŸå§‹æ¨¡å‹ =====
model.save("model.h5")
print("âœ… æ¨¡å‹å·²ä¿å­˜ä¸º model.h5")

# ===== å¯¼å‡ºæœªé‡åŒ–çš„ TFLite æ¨¡å‹ï¼ˆfloat32ï¼‰ =====
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
with open("model.tflite", "wb") as f:
    f.write(tflite_model)
print("âœ… æ¨¡å‹å·²ä¿å­˜ä¸º model.tflite")

# ===== int8 é‡åŒ–ç‰ˆæœ¬ï¼ˆå®Œæ•´æ•´æ•°é‡åŒ–ï¼‰ =====

# æä¾›ç”¨äºé‡åŒ–æ ¡å‡†çš„ä»£è¡¨æ€§æ•°æ®ç”Ÿæˆå™¨ï¼ˆåªè¦å‡ ç™¾ä¸ªæ ·æœ¬å³å¯ï¼‰
def representative_data_gen():
    for i in range(min(100, len(X))):             # ç”¨å‰100ä¸ªæ ·æœ¬è¿›è¡Œæ ¡å‡†
        data = X[i]
        data = np.expand_dims(data, axis=0).astype(np.float32)  # æ·»åŠ  batch ç»´åº¦
        yield [data]

# åˆ›å»ºé‡åŒ–è½¬æ¢å™¨
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]                  # å¯ç”¨é»˜è®¤ä¼˜åŒ–ï¼ˆåŒ…æ‹¬é‡åŒ–ï¼‰
converter.representative_dataset = representative_data_gen           # è®¾ç½®ä»£è¡¨æ€§æ•°æ®
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]  # ä½¿ç”¨å®Œæ•´ int8 é‡åŒ–
converter.inference_input_type = tf.uint8                            # è¾“å…¥ç±»å‹
converter.inference_output_type = tf.uint8                           # è¾“å‡ºç±»å‹

# è½¬æ¢å¹¶ä¿å­˜ int8 é‡åŒ–æ¨¡å‹
tflite_quant_model = converter.convert()
with open("model_int8.tflite", "wb") as f:
    f.write(tflite_quant_model)
print("âœ… int8 é‡åŒ–æ¨¡å‹å·²ä¿å­˜ä¸º model_int8.tflite")




# æ··åˆ int16 æƒé‡ + int8 æ¿€æ´»ï¼ˆè¾ƒå°‘ä½¿ç”¨ï¼‰
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,  # æ”¯æŒ int8 + éƒ¨åˆ† int16
]
# æ³¨æ„ï¼šä¸èƒ½è®¾ç½® input/output ä¸º int16ï¼Œè¿˜æ˜¯ uint8 æˆ– float32
tflite_mixed_model = converter.convert()

with open("model_mixed.tflite", "wb") as f:
    f.write(tflite_mixed_model)

print("âœ… æ··åˆ int16 æƒé‡ æ¨¡å‹å·²ä¿å­˜ä¸º model_mixed.tflite")









